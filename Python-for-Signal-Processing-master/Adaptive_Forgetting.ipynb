{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from IPython.display import display, clear_output\n",
    "import time \n",
    "from numpy import *\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous discussion  on linear regression, we saw that regularization  can help trade bias against  variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 6;b=1\n",
    "n=50\n",
    "\n",
    "x = linspace(0,1,n)\n",
    "y  = a*x + b +randn(n)\n",
    "p_,cov_ = polyfit(x,y,1,cov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_cone(ax,p_,cov_,x,alpha=0.95):\n",
    "    erra_=stats.norm(p_[0],sqrt(cov_[0,0])).interval(alpha)\n",
    "    errb_=stats.norm(p_[1],sqrt(cov_[1,1])).interval(alpha)\n",
    "    ax.fill_between(x,polyval([erra_[0],errb_[0]],x),\n",
    "                      polyval([erra_[1],errb_[1]],x),\n",
    "                      color='gray',alpha=.3)\n",
    "    \n",
    "def add_histogram(ax,x,y):\n",
    "    p_ = polyfit(x,y,1)\n",
    "    errs= polyval(p_,x)-y\n",
    "    ax.hist(errs,alpha=.3,normed=True)\n",
    "    rvs=stats.norm(mean(errs),std(errs))\n",
    "    xs = linspace(errs.min(),errs.max(),20)\n",
    "    ax.plot(xs,rvs.pdf(xs))\n",
    "    return errs\n",
    "    \n",
    "def add_fit(ax,x,y,**kwds):\n",
    "    p,cov_ = polyfit(x,y,1,cov=True)\n",
    "    ax.plot(x,polyval(p,x),**kwds)\n",
    "    return (p,cov_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,axs=subplots(1,2)\n",
    "fig.set_size_inches((10,3))\n",
    "outlier = [0.5,7]\n",
    "\n",
    "ax=axs[0]\n",
    "ax.plot(x,y,'o',alpha=.3)\n",
    "ax.plot(x,polyval(p_,x))\n",
    "erra_=stats.norm(p_[0],sqrt(cov_[0,0])).interval(.95)\n",
    "errb_=stats.norm(p_[1],sqrt(cov_[1,1])).interval(.95)\n",
    "ax.fill_between(x,polyval([erra_[0],errb_[0]],x),\n",
    "                  polyval([erra_[1],errb_[1]],x),\n",
    "                  color='gray',alpha=.3)\n",
    "ax.plot(outlier[0],outlier[1],'o',color='r')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.hist(polyval(p_,x)-y,alpha=.3)\n",
    "ax.vlines(outlier[1]-polyval(p_,outlier[0]),0,ax.get_ylim()[1],color='r',lw=3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try re-fitting with new data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameter wanders \n",
    "fig,axs=subplots(2,2,sharex=True,sharey=True)\n",
    "fig.set_size_inches((8,4))\n",
    "a_list = range(6,14,2)\n",
    "\n",
    "for a,ax in zip(a_list,axs.flat):\n",
    "    y  = a*x + b +randn(n)\n",
    "    p_,cov_ = polyfit(x,y,1,cov=True)\n",
    "    ax.plot(x,y,'o',alpha=.3)\n",
    "    ax.plot(x,polyval(p_,x))\n",
    "    ax.set_title(\"a=%g\"%a)\n",
    "    add_cone(ax,p_,cov_,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a0=6\n",
    "y0  = a0*x + b +randn(n)\n",
    "x0 = x[:]\n",
    "a1 = 15\n",
    "y1  = a1*x + b +randn(n)\n",
    "x1 = x[:]\n",
    "\n",
    "p_,cov_=polyfit(hstack([x,x]),hstack([y0,y1]),1,cov=True)\n",
    "\n",
    "fig,axs=subplots(1,2)\n",
    "fig.set_size_inches((8,4))\n",
    "ax=axs[0]\n",
    "add_cone(axs[0],p_,cov_,x)\n",
    "ax.plot(x,polyval([a0,b],x),label='a=6')\n",
    "ax.plot(x,polyval([a1,b],x),label='a=12')\n",
    "ax.plot(x,polyval(p_,x),label='all fit')\n",
    "ax.legend(loc=0)\n",
    "add_histogram(axs[1],hstack([x,x]),hstack([y0,y1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,axs=subplots(1,3)\n",
    "fig.set_size_inches((10,3))\n",
    "\n",
    "ax =axs[0]\n",
    "xc = []\n",
    "yc = []\n",
    "outliers=[]\n",
    "\n",
    "# allow for permutations on wander\n",
    "# idx=random.permutation(range(len(x)))\n",
    "# x1 = x1[idx]\n",
    "# y1 = y1[idx]\n",
    "\n",
    "# for baseline population \n",
    "p_base = polyfit(x0,y0,1)\n",
    "errs=polyval(p_base,x0)-y0\n",
    "rvs=stats.norm(mean(errs),std(errs))\n",
    "\n",
    "# convenience\n",
    "def eval_likelihood(i,j):\n",
    "    return rvs.pdf(j-polyval(p_base,i))\n",
    "\n",
    "for i,j in zip(x1,y1):\n",
    "    ax.plot(x,y0,'o',alpha=.3)\n",
    "    if eval_likelihood(i,j) < 0.05:\n",
    "        outliers.append((i,j))\n",
    "    else:\n",
    "        xc.append(i)\n",
    "        yc.append(j)\n",
    "    if outliers: \n",
    "        outlx = array(outliers)[:,0]\n",
    "        outly = array(outliers)[:,1]\n",
    "        ax.plot(outlx,outly,'or',alpha=.6)\n",
    "        if len(outliers)>5:\n",
    "            errs=add_histogram(axs[2],outlx,outly)\n",
    "            axs[2].vlines(j-polyval(polyfit(outlx,outly,1),i),0,0.3,lw=3.,color='r')\n",
    "            axs[2].set_title('%3.3g'%(stats.kstest(errs,'norm')[1]))\n",
    "            p_,cov_=add_fit(ax,outlx,outly,lw=3.,color='r')\n",
    "            add_cone(ax,p_,cov_,allx)\n",
    "\n",
    "    ax.plot(xc,yc,'o',color='r',alpha=.3)\n",
    "    allx = x.tolist()+xc\n",
    "    ally = y0.tolist()+yc\n",
    "    p_,cov_=add_fit(ax,allx,ally,color='k',lw=2)\n",
    "    add_cone(ax,p_,cov_,allx)\n",
    "    errs=add_histogram(axs[1],allx,ally)\n",
    "    axs[1].set_title('%3.3g'%(stats.kstest(errs,'norm')[1]))\n",
    "    axs[1].vlines(j-polyval(polyfit(allx,ally,1),i),0,0.3,lw=3.,color='r')\n",
    "    time.sleep(.1/2)\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "    ax.cla()\n",
    "    ax.axis(ymin=-2,ymax=15,xmin=0,xmax=x0.max())\n",
    "    axs[1].cla()\n",
    "    axs[2].cla()\n",
    "\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AdaptiveRegression(object):\n",
    "    def __init__(self,x0,y0):\n",
    "        self.x0,self.y0 = x0,y0\n",
    "        self.p0, self.cov0 = polyfit(x0,y0,1,cov=True)\n",
    "        self.errs = y0-polyval(self.p0,x0)\n",
    "        self.rvs = stats.norm(mean(errs),std(errs))\n",
    "    def predict(self,i):\n",
    "        return polyval(self.p0,i)\n",
    "    def likelihood(self,x,y):\n",
    "        return self.rvs.pdf(y-self.predict(x))\n",
    "    def update(self,x,y):\n",
    "        if isinstance(x,np.ndarray) and isinstance(y,np.ndarray):\n",
    "            self.x0,self.y0  = hstack([self.x0,y]),hstack([self.y0,y])\n",
    "        else:\n",
    "            self.x0,self.y0  = hstack([ self.x0,[x] ]),hstack([ self.y0,[y] ])\n",
    "        self.p0, self.cov0 = polyfit(self.x0,self.y0,1,cov=True)\n",
    "        self.errs = self.y0-polyval(self.p0,self.x0)\n",
    "        self.rvs = stats.norm(mean(errs),std(errs))\n",
    "    def plot(self,ax,**kwds):\n",
    "        ax.plot(self.x0,self.y0,marker='o',ls='none',alpha=.5,**kwds)\n",
    "        ax.plot(self.x0,self.predict(self.x0))\n",
    "    def add_cone(self,ax,alpha=0.95):\n",
    "        p_ = self.p0\n",
    "        cov_ = self.cov0\n",
    "        x = self.x0\n",
    "        erra_=stats.norm(p_[0],sqrt(cov_[0,0])).interval(alpha)\n",
    "        errb_=stats.norm(p_[1],sqrt(cov_[1,1])).interval(alpha)\n",
    "        ax.fill_between(x,polyval([erra_[0],errb_[0]],x),\n",
    "                          polyval([erra_[1],errb_[1]],x),\n",
    "                          color='gray',alpha=.3)\n",
    "    def add_histogram(self,ax):\n",
    "        errs =self.errs\n",
    "        ax.hist(errs,alpha=.3,normed=True)\n",
    "        xs = linspace(errs.min(),errs.max(),40)\n",
    "        ax.plot(xs,self.rvs.pdf(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax= subplots()\n",
    "ar=AdaptiveRegression(x0,y0)\n",
    "ar.plot(ax,color='r')\n",
    "ar.add_cone(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,axs= subplots(1,2)\n",
    "fig.set_size_inches((8,3))\n",
    "\n",
    "ar=AdaptiveRegression(x0,y0)\n",
    "for i,j in zip(x1,y1):\n",
    "    ax=axs[0]\n",
    "    ar.plot(ax,color='b')\n",
    "    ar.add_cone(ax)\n",
    "    ax.plot(i,j,'ro')\n",
    "    ar.update(i,j)\n",
    "    ar.add_histogram(axs[1])\n",
    "    axs[1].vlines(j-ar.predict(i),0,0.3,lw=3.,color='r')\n",
    "    time.sleep(.1/2)\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "    ax.cla()\n",
    "    ax.axis(ymin=-2,ymax=15,xmin=0,xmax=x0.max())\n",
    "    ax.set_title(repr(ar.p0))\n",
    "    axs[1].cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
